from __future__ import annotations

import importlib.util
import io
import json
import os
import re
import shutil
import subprocess
import textwrap
from contextlib import redirect_stderr, redirect_stdout
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from types import ModuleType
from typing import Callable, cast

from .schema import JsonValue
from .stage import StageContext, StageOutcome

_AUTOPOC_SCHEMA_VERSION = "exploit-autopoc-v1"
_DEFAULT_MAX_CANDIDATES = 3
_DEFAULT_REPRO = 3
_DEFAULT_LLM_TIMEOUT_S = 120.0
_MAX_GENERATED_PLUGIN_BYTES = 32_000
_AUTOPOC_LLM_RETRY_MAX_ATTEMPTS = 3
_AUTOPOC_LLM_RETRYABLE_STDERR_TOKENS: tuple[str, ...] = (
    "stream disconnected before completion",
    "error sending request",
    "connection reset by peer",
    "connection refused",
    "timed out",
    "timeout",
    "temporary failure",
    "503",
    "502",
    "429",
)
_DISALLOWED_PLUGIN_TOKENS: tuple[str, ...] = (
    "os.system(",
    "subprocess.",
    "pty.",
    "pexpect",
    "paramiko",
    "telnetlib",
    "multiprocessing",
    "threading.",
    "fork(",
    "exec(",
)


def _utc_now() -> str:
    return (
        datetime.now(tz=timezone.utc)
        .replace(microsecond=0)
        .isoformat()
        .replace("+00:00", "Z")
    )


def _read_manifest(run_dir: Path) -> dict[str, object] | None:
    path = run_dir / "manifest.json"
    if not path.is_file():
        return None
    try:
        raw = cast(object, json.loads(path.read_text(encoding="utf-8")))
    except Exception:
        return None
    if not isinstance(raw, dict):
        return None
    return cast(dict[str, object], raw)


def _profile_and_gate(
    manifest: dict[str, object] | None,
) -> tuple[str, dict[str, str] | None]:
    if manifest is None:
        return "analysis", None
    profile_any = manifest.get("profile")
    profile = (
        profile_any if isinstance(profile_any, str) and profile_any else "analysis"
    )
    gate_any = manifest.get("exploit_gate")
    if not isinstance(gate_any, dict):
        return profile, None
    gate_obj = cast(dict[str, object], gate_any)
    flag = gate_obj.get("flag")
    att = gate_obj.get("attestation")
    scope = gate_obj.get("scope")
    if not (isinstance(flag, str) and isinstance(att, str) and isinstance(scope, str)):
        return profile, None
    if not (flag and att and scope):
        return profile, None
    return profile, {"flag": flag, "attestation": att, "scope": scope}


def _safe_chain_token(value: str) -> str:
    token = re.sub(r"[^A-Za-z0-9._:-]", "_", value.strip())
    if not token:
        return "autopoc_chain"
    return token


def _safe_filename_token(value: str) -> str:
    token = re.sub(r"[^A-Za-z0-9._-]", "_", value.strip())
    if not token:
        return "autopoc_chain"
    return token


def _safe_float(value: object, default: float = 0.0) -> float:
    if isinstance(value, bool):
        return default
    if isinstance(value, (int, float)):
        return float(value)
    if isinstance(value, str):
        try:
            return float(value)
        except ValueError:
            return default
    return default


def _env_float(name: str, *, default: float, min_value: float, max_value: float) -> float:
    raw = os.environ.get(name)
    if raw is None:
        return default
    try:
        value = float(raw)
    except Exception:
        return default
    if value < min_value:
        return min_value
    if value > max_value:
        return max_value
    return value


def _env_int(name: str, *, default: int, min_value: int, max_value: int) -> int:
    raw = os.environ.get(name)
    if raw is None:
        return default
    try:
        value = int(raw)
    except Exception:
        return default
    if value < min_value:
        return min_value
    if value > max_value:
        return max_value
    return value


def _priority_rank(value: object) -> int:
    if not isinstance(value, str):
        return 9
    if value == "high":
        return 0
    if value == "medium":
        return 1
    if value == "low":
        return 2
    return 9


def _priority_label_from_score(score: float) -> str:
    normalized = max(0.0, min(1.0, float(score)))
    if normalized >= 0.82:
        return "high"
    if normalized >= 0.55:
        return "medium"
    return "low"


def _safe_string_list(value: object, *, max_items: int = 8) -> list[str]:
    if not isinstance(value, list):
        return []
    out: list[str] = []
    for item_any in cast(list[object], value):
        if not isinstance(item_any, str):
            continue
        item = " ".join(item_any.split()).strip()
        if not item:
            continue
        out.append(item)
        if len(out) >= max_items:
            break
    return out


def _load_findings_candidates(run_dir: Path) -> list[dict[str, object]]:
    path = run_dir / "stages" / "findings" / "exploit_candidates.json"
    if not path.is_file():
        return []
    try:
        raw = cast(object, json.loads(path.read_text(encoding="utf-8")))
    except Exception:
        return []
    if not isinstance(raw, dict):
        return []
    candidates_any = cast(dict[str, object], raw).get("candidates")
    if not isinstance(candidates_any, list):
        return []
    out: list[dict[str, object]] = []
    for item_any in cast(list[object], candidates_any):
        if isinstance(item_any, dict):
            out.append(cast(dict[str, object], item_any))
    return out


def _load_llm_chain_candidates(run_dir: Path) -> list[dict[str, object]]:
    path = run_dir / "stages" / "llm_synthesis" / "llm_synthesis.json"
    if not path.is_file():
        return []
    try:
        raw = cast(object, json.loads(path.read_text(encoding="utf-8")))
    except Exception:
        return []
    if not isinstance(raw, dict):
        return []

    claims_any = cast(dict[str, object], raw).get("claims")
    if not isinstance(claims_any, list):
        return []

    out: list[dict[str, object]] = []
    for idx, claim_any in enumerate(cast(list[object], claims_any), start=1):
        if not isinstance(claim_any, dict):
            continue
        claim = cast(dict[str, object], claim_any)
        claim_type = str(claim.get("claim_type", ""))
        if not claim_type.startswith("llm_chain."):
            continue
        value_any = claim.get("value")
        if not isinstance(value_any, dict):
            continue
        value = cast(dict[str, object], value_any)
        chain_id_raw = str(value.get("chain_id", "")).strip() or claim_type[len("llm_chain.") :]
        chain_id = _safe_chain_token(chain_id_raw)
        if not chain_id:
            continue

        score = _safe_float(claim.get("confidence"), default=0.65)
        refs = _safe_string_list(claim.get("evidence_refs"), max_items=12)
        if not refs:
            refs = _safe_string_list(value.get("evidence_refs"), max_items=12)
        if not refs:
            continue

        hypothesis = " ".join(str(value.get("hypothesis", "")).split()).strip()
        impact = " ".join(str(value.get("impact", "")).split()).strip()
        attack_steps = _safe_string_list(value.get("attack_steps"), max_items=6)
        preconditions = _safe_string_list(value.get("preconditions"), max_items=6)

        out.append(
            {
                "candidate_id": f"candidate:llm-chain:{chain_id}:{idx}",
                "source": "llm_chain",
                "chain_id": chain_id,
                "priority": _priority_label_from_score(score),
                "score": round(max(0.0, min(1.0, score)), 4),
                "families": ["llm_chain_hypothesis"],
                "summary": hypothesis or f"LLM chain hypothesis for {chain_id}.",
                "attack_hypothesis": hypothesis,
                "expected_impact": [impact] if impact else [],
                "validation_plan": attack_steps if attack_steps else preconditions,
                "evidence_refs": refs,
                "path": refs[0] if refs else "",
            }
        )
    return out


def _promote_non_chain_candidates(
    candidates: list[dict[str, object]],
) -> list[dict[str, object]]:
    ranked = sorted(
        candidates,
        key=lambda item: (
            _priority_rank(item.get("priority")),
            -_safe_float(item.get("score"), default=0.0),
            str(item.get("candidate_id", "")),
        ),
    )
    promoted: list[dict[str, object]] = []
    for idx, item in enumerate(ranked, start=1):
        score = _safe_float(item.get("score"), default=0.0)
        if score < 0.55:
            continue
        candidate_id = str(item.get("candidate_id", "")).strip() or f"promoted-{idx}"
        base = re.sub(r"[^A-Za-z0-9._:-]", "_", candidate_id)
        if not base:
            base = f"promoted-{idx}"
        chain_id = _safe_chain_token(f"synthetic_chain:{base}")

        promoted_item = dict(item)
        promoted_item["chain_id"] = chain_id
        promoted_item["source"] = (
            str(item.get("source", "")).strip() + "+promoted_non_chain"
            if str(item.get("source", "")).strip()
            else "promoted_non_chain"
        )
        summary = str(item.get("summary", "")).strip()
        if summary:
            promoted_item["summary"] = summary + " (promoted from non-chain candidate)"
        else:
            promoted_item["summary"] = "Promoted non-chain exploit candidate."
        promoted.append(promoted_item)
    return promoted


def _dedupe_candidates(candidates: list[dict[str, object]]) -> list[dict[str, object]]:
    out: list[dict[str, object]] = []
    seen: set[tuple[str, str]] = set()
    for item in candidates:
        chain_id = str(item.get("chain_id", "")).strip()
        candidate_id = str(item.get("candidate_id", "")).strip()
        if not chain_id:
            continue
        key = (chain_id, candidate_id)
        if key in seen:
            continue
        seen.add(key)
        out.append(item)
    return out


def _load_candidates(run_dir: Path) -> list[dict[str, object]]:
    findings_candidates = _load_findings_candidates(run_dir)
    chain_backed: list[dict[str, object]] = []
    non_chain: list[dict[str, object]] = []
    for candidate in findings_candidates:
        chain_id_any = candidate.get("chain_id")
        if isinstance(chain_id_any, str) and chain_id_any.strip():
            chain_backed.append(candidate)
        else:
            non_chain.append(candidate)

    llm_chain_candidates = _load_llm_chain_candidates(run_dir)
    merged = _dedupe_candidates(chain_backed + llm_chain_candidates)
    if merged:
        return merged

    promoted = _promote_non_chain_candidates(non_chain)
    return _dedupe_candidates(promoted)


def _select_candidates(
    candidates: list[dict[str, object]], *, max_candidates: int
) -> list[dict[str, object]]:
    ranked = sorted(
        candidates,
        key=lambda item: (
            _priority_rank(item.get("priority")),
            -_safe_float(item.get("score"), default=0.0),
            str(item.get("chain_id", "")),
            str(item.get("candidate_id", "")),
        ),
    )
    if max_candidates <= 0:
        return []
    return ranked[:max_candidates]


def _load_exploit_runner_fn() -> Callable[[Path, Path, str, int], int] | None:
    runner_path = Path(__file__).resolve().parents[2] / "exploit_runner.py"
    if not runner_path.is_file():
        return None
    spec = importlib.util.spec_from_file_location(
        "_aiedge_exploit_runner", str(runner_path)
    )
    if spec is None or spec.loader is None:
        return None
    mod = importlib.util.module_from_spec(spec)
    cast(ModuleType, mod)
    spec.loader.exec_module(mod)
    fn_any = getattr(mod, "run_exploit", None)
    if not callable(fn_any):
        return None
    fn = cast(Callable[..., object], fn_any)

    def invoke(run_dir: Path, exploit_dir: Path, chain_id: str, repro: int) -> int:
        code_any = fn(
            run_dir=run_dir,
            exploit_dir=exploit_dir,
            chain_id=chain_id,
            repro=repro,
        )
        if isinstance(code_any, int):
            return int(code_any)
        return 1

    return invoke


def _plugin_source(
    *,
    chain_id: str,
    target_service: str,
    candidate_id: str,
    candidate_summary: str,
    fallback_read_rel: str,
) -> str:
    chain_literal = json.dumps(chain_id)
    service_literal = json.dumps(target_service)
    candidate_literal = json.dumps(candidate_id)
    summary_literal = json.dumps(candidate_summary)
    fallback_read_literal = json.dumps(fallback_read_rel)
    return textwrap.dedent(
        f"""\
        from __future__ import annotations

        import hashlib
        import socket
        from datetime import datetime, timezone
        from pathlib import Path


        class PoCResult:
            def __init__(self, success: bool, proof_type: str, proof_evidence: str, timestamp: str) -> None:
                self.success = success
                self.proof_type = proof_type
                self.proof_evidence = proof_evidence
                self.timestamp = timestamp


        def _utc_now() -> str:
            return datetime.now(tz=timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


        class PoC:
            chain_id = {chain_literal}
            target_service = {service_literal}
            fallback_read_rel = {fallback_read_literal}

            def setup(self, target_ip: str, target_port: int, *, context: dict[str, object]) -> None:
                self.target_ip = target_ip
                self.target_port = target_port
                self.context = context

            def execute(self) -> PoCResult:
                timestamp = _utc_now()
                evidence_prefix = (
                    "autopoc_mode=deterministic_nonweaponized "
                    + "candidate_id="
                    + {candidate_literal}
                    + " summary="
                    + {summary_literal}
                    + " probe=tcp_banner"
                )

                try:
                    sock = socket.create_connection((self.target_ip, int(self.target_port)), timeout=2.0)
                    sock.settimeout(2.0)
                    try:
                        sock.sendall(b"\\r\\n")
                    except Exception:
                        pass
                    banner = sock.recv(512)
                    sock.close()
                    digest = hashlib.sha256(banner).hexdigest()
                    evidence = (
                        evidence_prefix
                        + f" port={{self.target_port}} bytes={{len(banner)}} readback_hash={{digest}}"
                    )
                    return PoCResult(
                        success=True,
                        proof_type="arbitrary_read",
                        proof_evidence=evidence,
                        timestamp=timestamp,
                    )
                except Exception as exc:
                    net_err = f"{{type(exc).__name__}}:{{exc}}"
                    fallback_rel = self.fallback_read_rel
                    run_root_raw = self.context.get("run_dir", "")
                    run_root = str(run_root_raw) if isinstance(run_root_raw, str) else ""
                    if fallback_rel and run_root:
                        try:
                            run_root_path = Path(run_root).resolve()
                            candidate = (run_root_path / fallback_rel).resolve()
                            try:
                                _ = candidate.relative_to(run_root_path)
                            except Exception:
                                candidate = None

                            if candidate is not None and candidate.is_file():
                                blob = candidate.read_bytes()[:4096]
                                digest = hashlib.sha256(blob).hexdigest()
                                evidence = (
                                    evidence_prefix
                                    + f" port={{self.target_port}} bytes={{len(blob)}} "
                                    + f"fallback=file_read path={{fallback_rel}} readback_hash={{digest}} "
                                    + f"network_error={{net_err}}"
                                )
                                return PoCResult(
                                    success=True,
                                    proof_type="arbitrary_read",
                                    proof_evidence=evidence,
                                    timestamp=timestamp,
                                )
                        except Exception as fexc:
                            evidence = (
                                evidence_prefix
                                + f" port={{self.target_port}} bytes=0 readback_hash=none "
                                + f"network_error={{net_err}} fallback_error={{type(fexc).__name__}}:{{fexc}}"
                            )
                            return PoCResult(
                                success=False,
                                proof_type="arbitrary_read",
                                proof_evidence=evidence,
                                timestamp=timestamp,
                            )

                    evidence = (
                        evidence_prefix
                        + f" port={{self.target_port}} bytes=0 readback_hash=none "
                        + f"network_error={{net_err}} fallback=unavailable"
                    )
                    return PoCResult(
                        success=False,
                        proof_type="arbitrary_read",
                        proof_evidence=evidence,
                        timestamp=timestamp,
                    )

            def cleanup(self) -> None:
                return
        """
    )


def _llm_plugin_prompt(
    *,
    chain_id: str,
    target_service: str,
    candidate_id: str,
    candidate_summary: str,
) -> str:
    return textwrap.dedent(
        f"""\
        Generate a single Python module for a non-weaponized firmware PoC probe plugin.
        Return ONLY Python code (no markdown fences).

        Mandatory constraints:
        - Define class PoCResult(success, proof_type, proof_evidence, timestamp).
        - Define class PoC with:
          - chain_id = {json.dumps(chain_id)}
          - target_service = {json.dumps(target_service)}
          - methods: setup(self, target_ip, target_port, *, context), execute(self), cleanup(self)
        - execute() must be non-weaponized:
          - read-only network probe only (no shell commands, no command injection payloads, no persistence).
          - no subprocess/os.system/pty/pexpect/paramiko/telnetlib usage.
          - include evidence prefix exactly:
            "autopoc_mode=llm_nonweaponized candidate_id={candidate_id} summary={candidate_summary} probe=tcp_banner"
          - evidence must contain readback_hash field (sha256 of observed bytes or "none").
        - Keep module self-contained and deterministic.
        - Keep plugin compatible with exploit_runner.py expectations.
        """
    )


def _extract_python_source(text: str) -> str:
    stripped = text.strip()
    if not stripped:
        return ""

    fences = re.findall(
        r"```(?:python)?\s*\n(.*?)```",
        stripped,
        flags=re.IGNORECASE | re.DOTALL,
    )
    if fences:
        return fences[0].strip() + "\n"
    return stripped + ("\n" if not stripped.endswith("\n") else "")


def _validate_plugin_source(
    source: str, *, chain_id: str, target_service: str
) -> list[str]:
    limits: list[str] = []
    if not source.strip():
        limits.append("empty_source")
        return limits

    if len(source.encode("utf-8")) > _MAX_GENERATED_PLUGIN_BYTES:
        limits.append("source_too_large")

    for token in _DISALLOWED_PLUGIN_TOKENS:
        if token in source:
            limits.append(f"disallowed_token:{token}")

    if "class PoCResult" not in source:
        limits.append("missing_class_PoCResult")
    if "class PoC" not in source:
        limits.append("missing_class_PoC")
    for method in ("def setup(", "def execute(", "def cleanup("):
        if method not in source:
            limits.append(f"missing_method:{method}")

    if f'chain_id = "{chain_id}"' not in source and f"chain_id = '{chain_id}'" not in source:
        limits.append("chain_id_mismatch")
    if (
        f'target_service = "{target_service}"' not in source
        and f"target_service = '{target_service}'" not in source
    ):
        limits.append("target_service_mismatch")

    try:
        _ = compile(source, "<autopoc_generated>", "exec")
    except Exception as exc:
        limits.append(f"syntax_error:{type(exc).__name__}")

    return sorted(set(limits))


def _run_codex_exec(
    *,
    prompt: str,
    run_dir: Path,
    timeout_s: float,
) -> dict[str, object]:
    if not shutil.which("codex"):
        return {
            "status": "missing_cli",
            "stdout": "",
            "stderr": "codex executable not found",
            "argv": [],
        }

    timeout = _env_float(
        "AIEDGE_AUTOPOC_LLM_TIMEOUT_S",
        default=max(1.0, min(float(timeout_s), 180.0)),
        min_value=10.0,
        max_value=300.0,
    )
    base_argv = [
        "codex",
        "exec",
        "--ephemeral",
        "-s",
        "read-only",
        "-C",
        str(run_dir),
    ]
    argv = base_argv + [prompt]

    attempts: list[dict[str, object]] = []

    def _exec_once(cmd: list[str]) -> subprocess.CompletedProcess[str]:
        cp = subprocess.run(
            cmd,
            check=False,
            capture_output=True,
            text=True,
            timeout=timeout,
            stdin=subprocess.DEVNULL,
        )
        attempts.append(
            {
                "argv": list(cmd),
                "returncode": int(cp.returncode),
                "stdout": cp.stdout or "",
                "stderr": cp.stderr or "",
            }
        )
        return cp

    max_attempts = _env_int(
        "AIEDGE_AUTOPOC_LLM_MAX_ATTEMPTS",
        default=max(1, int(_AUTOPOC_LLM_RETRY_MAX_ATTEMPTS)),
        min_value=1,
        max_value=8,
    )
    cp: subprocess.CompletedProcess[str] | None = None
    use_skip_git_repo_check = False
    retryable_error_detected = False

    for attempt_idx in range(max_attempts):
        cmd = (
            base_argv + ["--skip-git-repo-check", prompt]
            if use_skip_git_repo_check
            else list(argv)
        )
        try:
            cp = _exec_once(cmd)
        except subprocess.TimeoutExpired as exc:
            attempts.append(
                {
                    "argv": list(cmd),
                    "returncode": -1,
                    "stdout": (exc.stdout if isinstance(exc.stdout, str) else "") or "",
                    "stderr": (exc.stderr if isinstance(exc.stderr, str) else "") or "",
                    "exception": "TimeoutExpired",
                }
            )
            if attempt_idx + 1 < max_attempts:
                continue
            return {
                "status": "timeout",
                "stdout": (exc.stdout if isinstance(exc.stdout, str) else "") or "",
                "stderr": (exc.stderr if isinstance(exc.stderr, str) else "") or "",
                "argv": list(cmd),
                "attempts": attempts,
                "returncode": -1,
            }
        except Exception as exc:
            return {
                "status": "error",
                "stdout": "",
                "stderr": f"{type(exc).__name__}: {exc}",
                "argv": list(cmd),
                "attempts": attempts,
                "returncode": -1,
            }

        stderr_lc = (cp.stderr or "").lower()
        if cp.returncode == 0:
            break

        if "skip-git-repo-check" in stderr_lc and not use_skip_git_repo_check:
            use_skip_git_repo_check = True
            continue

        retryable_error_detected = any(
            token in stderr_lc for token in _AUTOPOC_LLM_RETRYABLE_STDERR_TOKENS
        )
        if retryable_error_detected:
            continue

        break

    if cp is None:
        return {
            "status": "error",
            "stdout": "",
            "stderr": "codex autopoc execution did not produce a process result",
            "argv": list(argv),
            "attempts": attempts,
            "returncode": -1,
        }

    status = "ok" if cp.returncode == 0 else "nonzero_exit"
    return {
        "status": status,
        "stdout": cp.stdout or "",
        "stderr": cp.stderr or "",
        "argv": list(attempts[-1]["argv"]) if attempts else list(argv),
        "attempts": attempts,
        "returncode": int(cp.returncode),
        "retryable_error_detected": bool(retryable_error_detected),
    }


def _candidate_text(value: object, *, fallback: str) -> str:
    if isinstance(value, str):
        trimmed = " ".join(value.split())
        if trimmed:
            return trimmed
    return fallback


def _target_service_for_candidate(candidate: dict[str, object]) -> str:
    families_any = candidate.get("families")
    families: list[str] = []
    if isinstance(families_any, list):
        families = [x for x in cast(list[object], families_any) if isinstance(x, str)]
    families_lower = " ".join(families).lower()
    if "ssh" in families_lower:
        return "ssh"
    if "http" in families_lower or "cgi" in families_lower:
        return "http"
    return "tcp"


def _fallback_read_rel_path(run_dir: Path, candidate: dict[str, object]) -> str:
    refs_any = candidate.get("evidence_refs")
    if not isinstance(refs_any, list):
        return ""

    for ref_any in cast(list[object], refs_any):
        if not isinstance(ref_any, str):
            continue
        rel = ref_any.replace("\\", "/").strip()
        if not rel or rel.startswith("/"):
            continue
        if rel.startswith("../"):
            continue
        path = (run_dir / rel).resolve()
        try:
            _ = path.relative_to(run_dir.resolve())
        except Exception:
            continue
        if path.is_file():
            return rel
    return ""


def _safe_rel(run_dir: Path, path: Path) -> str:
    try:
        return path.resolve().relative_to(run_dir.resolve()).as_posix()
    except Exception:
        return str(path)


def _write_json(path: Path, payload: dict[str, JsonValue]) -> None:
    _ = path.write_text(
        json.dumps(payload, indent=2, sort_keys=True, ensure_ascii=True) + "\n",
        encoding="utf-8",
    )


def _write_text(path: Path, text: str) -> None:
    _ = path.write_text(text, encoding="utf-8")


@dataclass(frozen=True)
class ExploitAutoPoCStage:
    max_candidates: int = _DEFAULT_MAX_CANDIDATES
    repro: int = _DEFAULT_REPRO
    no_llm: bool = False
    llm_timeout_s: float = _DEFAULT_LLM_TIMEOUT_S

    @property
    def name(self) -> str:
        return "exploit_autopoc"

    def run(self, ctx: StageContext) -> StageOutcome:
        run_dir = ctx.run_dir
        stage_dir = run_dir / "stages" / "exploit_autopoc"
        stage_dir.mkdir(parents=True, exist_ok=True)
        summary_path = stage_dir / "exploit_autopoc.json"
        plugins_dir = stage_dir / "generated_plugins"
        logs_dir = stage_dir / "runner_logs"
        llm_dir = stage_dir / "llm_codegen"
        plugins_dir.mkdir(parents=True, exist_ok=True)
        logs_dir.mkdir(parents=True, exist_ok=True)
        llm_dir.mkdir(parents=True, exist_ok=True)

        manifest = _read_manifest(run_dir)
        profile, gate = _profile_and_gate(manifest)
        base_payload: dict[str, JsonValue] = {
            "schema_version": _AUTOPOC_SCHEMA_VERSION,
            "generated_at": _utc_now(),
            "profile": profile,
            "config": {
                "max_candidates": int(max(0, self.max_candidates)),
                "repro": int(max(1, self.repro)),
                "llm_enabled": bool(not self.no_llm),
                "llm_timeout_s": float(max(1.0, self.llm_timeout_s)),
            },
            "attempts": [],
            "summary": {
                "candidate_count": 0,
                "chain_backed_candidates": 0,
                "llm_seeded_candidates": 0,
                "promoted_non_chain_candidates": 0,
                "selected_count": 0,
                "attempted": 0,
                "runner_pass": 0,
                "runner_nonpass": 0,
                "bundle_count": 0,
                "llm_generated": 0,
                "template_fallback": 0,
            },
            "limitations": [],
        }

        evidence: list[JsonValue] = [
            {"path": "manifest.json"},
            {"path": "stages/exploit_autopoc"},
            {"path": "stages/exploit_autopoc/exploit_autopoc.json"},
        ]

        if profile != "exploit":
            payload = dict(base_payload)
            payload["status"] = "skipped"
            payload["limitations"] = cast(
                JsonValue,
                ["exploit_autopoc skipped: profile is not exploit."],
            )
            _write_json(summary_path, cast(dict[str, JsonValue], payload))
            return StageOutcome(
                status="skipped",
                details={
                    "profile": profile,
                    "summary": cast(dict[str, JsonValue], payload["summary"]),
                    "evidence": evidence,
                },
                limitations=["exploit_autopoc skipped: profile is not exploit."],
            )

        if gate is None:
            payload = dict(base_payload)
            payload["status"] = "failed"
            payload["limitations"] = cast(
                JsonValue,
                ["exploit_autopoc blocked: exploit_gate is missing or malformed."],
            )
            _write_json(summary_path, cast(dict[str, JsonValue], payload))
            return StageOutcome(
                status="failed",
                details={
                    "profile": profile,
                    "summary": cast(dict[str, JsonValue], payload["summary"]),
                    "evidence": evidence,
                },
                limitations=["exploit_autopoc blocked: exploit_gate is missing."],
            )

        if gate.get("scope") != "lab-only" or gate.get("attestation") != "authorized":
            payload = dict(base_payload)
            payload["status"] = "failed"
            payload["limitations"] = cast(
                JsonValue,
                [
                    "exploit_autopoc blocked: requires exploit_gate.scope=lab-only and exploit_gate.attestation=authorized."
                ],
            )
            payload["exploit_gate"] = cast(
                JsonValue, cast(dict[str, object], dict(gate))
            )
            _write_json(summary_path, cast(dict[str, JsonValue], payload))
            return StageOutcome(
                status="failed",
                details={
                    "profile": profile,
                    "summary": cast(dict[str, JsonValue], payload["summary"]),
                    "evidence": evidence,
                },
                limitations=[
                    "exploit_autopoc blocked: gate scope/attestation do not satisfy lab-only authorized policy."
                ],
            )

        runner = _load_exploit_runner_fn()
        if runner is None:
            payload = dict(base_payload)
            payload["status"] = "failed"
            payload["limitations"] = cast(
                JsonValue,
                ["exploit_autopoc blocked: exploit_runner.py run_exploit unavailable."],
            )
            _write_json(summary_path, cast(dict[str, JsonValue], payload))
            return StageOutcome(
                status="failed",
                details={
                    "profile": profile,
                    "summary": cast(dict[str, JsonValue], payload["summary"]),
                    "evidence": evidence,
                },
                limitations=["exploit_autopoc blocked: exploit runner unavailable."],
            )

        candidates_all = _load_candidates(run_dir)
        chain_backed_candidates = sum(
            1
            for item in candidates_all
            if isinstance(item.get("source"), str)
            and "promoted_non_chain" not in str(item.get("source"))
        )
        llm_seeded_candidates = sum(
            1
            for item in candidates_all
            if isinstance(item.get("source"), str)
            and str(item.get("source")) == "llm_chain"
        )
        promoted_non_chain_candidates = sum(
            1
            for item in candidates_all
            if isinstance(item.get("source"), str)
            and "promoted_non_chain" in str(item.get("source"))
        )
        selected = _select_candidates(
            candidates_all, max_candidates=int(max(0, self.max_candidates))
        )

        if not selected:
            payload = dict(base_payload)
            payload["status"] = "skipped"
            payload["summary"] = cast(
                JsonValue,
                {
                    "candidate_count": len(candidates_all),
                    "chain_backed_candidates": int(chain_backed_candidates),
                    "llm_seeded_candidates": int(llm_seeded_candidates),
                    "promoted_non_chain_candidates": int(promoted_non_chain_candidates),
                    "selected_count": 0,
                    "attempted": 0,
                    "runner_pass": 0,
                    "runner_nonpass": 0,
                    "bundle_count": 0,
                    "llm_generated": 0,
                    "template_fallback": 0,
                },
            )
            payload["limitations"] = cast(
                JsonValue,
                [
                    "exploit_autopoc skipped: no exploit candidates were available after chain/LLM/promotion selection."
                ],
            )
            _write_json(summary_path, cast(dict[str, JsonValue], payload))
            return StageOutcome(
                status="skipped",
                details={
                    "profile": profile,
                    "summary": cast(dict[str, JsonValue], payload["summary"]),
                    "evidence": evidence,
                },
                limitations=[
                    "exploit_autopoc skipped: no exploit candidates after chain/LLM/promotion selection."
                ],
            )

        attempts: list[dict[str, JsonValue]] = []
        bundle_refs: list[str] = []
        limits: list[str] = []
        runner_pass = 0
        runner_nonpass = 0
        llm_generated = 0
        template_fallback = 0

        for idx, candidate in enumerate(selected, start=1):
            chain_raw = _candidate_text(
                candidate.get("chain_id"), fallback=f"auto-{idx}"
            )
            chain_id = _safe_chain_token(chain_raw)
            candidate_id = _candidate_text(
                candidate.get("candidate_id"), fallback=f"candidate-{idx}"
            )
            summary = _candidate_text(
                candidate.get("summary"), fallback="autopoc generated probe"
            )
            target_service = _target_service_for_candidate(candidate)
            fallback_read_rel = _fallback_read_rel_path(run_dir, candidate)
            plugin_name = _safe_filename_token(chain_id) + ".py"
            plugin_path = plugins_dir / plugin_name

            source = _plugin_source(
                chain_id=chain_id,
                target_service=target_service,
                candidate_id=candidate_id,
                candidate_summary=summary,
                fallback_read_rel=fallback_read_rel,
            )
            generator = "template"
            generator_reason = "deterministic_template"
            llm_meta_rel = ""

            if self.no_llm:
                template_fallback += 1
                generator_reason = "no_llm_mode"
            else:
                llm_name = _safe_filename_token(chain_id)
                prompt_path = llm_dir / f"{llm_name}.prompt.txt"
                raw_path = llm_dir / f"{llm_name}.raw.txt"
                meta_path = llm_dir / f"{llm_name}.meta.json"
                prompt = _llm_plugin_prompt(
                    chain_id=chain_id,
                    target_service=target_service,
                    candidate_id=candidate_id,
                    candidate_summary=summary,
                )
                _write_text(prompt_path, prompt)

                llm_exec = _run_codex_exec(
                    prompt=prompt,
                    run_dir=run_dir,
                    timeout_s=float(max(1.0, self.llm_timeout_s)),
                )
                stdout = str(llm_exec.get("stdout", ""))
                stderr = str(llm_exec.get("stderr", ""))
                _write_text(
                    raw_path,
                    "\n".join(
                        [
                            "### stdout",
                            stdout,
                            "",
                            "### stderr",
                            stderr,
                            "",
                        ]
                    ),
                )

                llm_source = _extract_python_source(stdout)
                llm_validation = _validate_plugin_source(
                    llm_source, chain_id=chain_id, target_service=target_service
                )
                llm_status = str(llm_exec.get("status", "error"))

                meta_payload: dict[str, JsonValue] = {
                    "status": llm_status,
                    "chain_id": chain_id,
                    "candidate_id": candidate_id,
                    "target_service": target_service,
                    "returncode": int(cast(int, llm_exec.get("returncode", -1)))
                    if isinstance(llm_exec.get("returncode"), int)
                    else -1,
                    "argv": cast(
                        list[JsonValue],
                        cast(list[object], list(cast(list[object], llm_exec.get("argv", [])))),
                    )
                    if isinstance(llm_exec.get("argv"), list)
                    else cast(list[JsonValue], cast(list[object], [])),
                    "validation": cast(
                        list[JsonValue], cast(list[object], list(llm_validation))
                    ),
                    "attempt_count": int(
                        len(cast(list[object], llm_exec.get("attempts", [])))
                        if isinstance(llm_exec.get("attempts"), list)
                        else 0
                    ),
                    "prompt_path": _safe_rel(run_dir, prompt_path),
                    "raw_path": _safe_rel(run_dir, raw_path),
                }
                _write_json(meta_path, meta_payload)
                llm_meta_rel = _safe_rel(run_dir, meta_path)
                evidence.append({"path": _safe_rel(run_dir, prompt_path)})
                evidence.append({"path": _safe_rel(run_dir, raw_path)})
                evidence.append({"path": llm_meta_rel})

                if llm_status == "ok" and not llm_validation:
                    source = llm_source
                    generator = "llm"
                    generator_reason = "llm_codegen_ok"
                    llm_generated += 1
                else:
                    template_fallback += 1
                    generator_reason = f"fallback:{llm_status}"
                    if llm_validation:
                        limits.append(
                            f"autopoc llm validation fallback for chain_id={chain_id}: "
                            + ",".join(llm_validation)
                        )
                    else:
                        limits.append(
                            f"autopoc llm fallback for chain_id={chain_id}: status={llm_status}"
                        )

            _ = plugin_path.write_text(source, encoding="utf-8")

            runner_buf = io.StringIO()
            with redirect_stdout(runner_buf), redirect_stderr(runner_buf):
                rc = runner(
                    run_dir=run_dir,
                    exploit_dir=plugins_dir,
                    chain_id=chain_id,
                    repro=int(max(1, self.repro)),
                )
            runner_output = runner_buf.getvalue()

            log_path = logs_dir / f"{_safe_filename_token(chain_id)}.log"
            _ = log_path.write_text(runner_output, encoding="utf-8")

            safe_chain_dir = re.sub(r"[^A-Za-z0-9._-]", "_", chain_id.strip())
            if not safe_chain_dir:
                safe_chain_dir = "unknown"
            bundle_path = (
                run_dir
                / "exploits"
                / f"chain_{safe_chain_dir}"
                / "evidence_bundle.json"
            )
            bundle_rel = ""
            if bundle_path.is_file():
                bundle_rel = _safe_rel(run_dir, bundle_path)
                bundle_refs.append(bundle_rel)
                evidence.append({"path": bundle_rel})

            plugin_rel = _safe_rel(run_dir, plugin_path)
            log_rel = _safe_rel(run_dir, log_path)
            evidence.append({"path": plugin_rel})
            evidence.append({"path": log_rel})

            if rc == 0:
                runner_pass += 1
            else:
                runner_nonpass += 1

            attempt_obj: dict[str, JsonValue] = {
                "chain_id": chain_id,
                "candidate_id": candidate_id,
                "priority": _candidate_text(
                    candidate.get("priority"), fallback="unknown"
                ),
                "score": float(_safe_float(candidate.get("score"), default=0.0)),
                "plugin_path": plugin_rel,
                "runner_log": log_rel,
                "runner_exit_code": int(rc),
                "bundle_path": bundle_rel,
                "generator": generator,
                "generator_reason": generator_reason,
                "llm_meta_path": llm_meta_rel,
                "fallback_read_rel": fallback_read_rel,
            }
            attempts.append(attempt_obj)

            if rc != 0:
                limits.append(
                    f"autopoc runner non-pass for chain_id={chain_id} (exit={rc})"
                )

        stage_status = "ok" if runner_nonpass == 0 else "partial"
        summary_payload: dict[str, JsonValue] = {
            "candidate_count": len(candidates_all),
            "chain_backed_candidates": int(chain_backed_candidates),
            "llm_seeded_candidates": int(llm_seeded_candidates),
            "promoted_non_chain_candidates": int(promoted_non_chain_candidates),
            "selected_count": len(selected),
            "attempted": len(attempts),
            "runner_pass": int(runner_pass),
            "runner_nonpass": int(runner_nonpass),
            "bundle_count": len(bundle_refs),
            "llm_generated": int(llm_generated),
            "template_fallback": int(template_fallback),
        }

        payload: dict[str, JsonValue] = {
            "schema_version": _AUTOPOC_SCHEMA_VERSION,
            "generated_at": _utc_now(),
            "profile": profile,
            "exploit_gate": cast(JsonValue, cast(dict[str, object], dict(gate))),
            "status": stage_status,
            "config": {
                "max_candidates": int(max(0, self.max_candidates)),
                "repro": int(max(1, self.repro)),
                "llm_enabled": bool(not self.no_llm),
                "llm_timeout_s": float(max(1.0, self.llm_timeout_s)),
            },
            "attempts": cast(list[JsonValue], cast(list[object], attempts)),
            "summary": summary_payload,
            "limitations": cast(
                list[JsonValue], cast(list[object], sorted(set(limits)))
            ),
        }
        _write_json(summary_path, payload)

        detail_summary: dict[str, JsonValue] = {
            "profile": profile,
            "summary": summary_payload,
            "attempts": cast(list[JsonValue], cast(list[object], attempts)),
            "bundle_refs": cast(list[JsonValue], cast(list[object], sorted(bundle_refs))),
            "evidence": cast(list[JsonValue], cast(list[object], evidence)),
        }
        outcome_status = "ok" if stage_status == "ok" else "partial"
        return StageOutcome(
            status=outcome_status,
            details=detail_summary,
            limitations=sorted(set(limits)),
        )
